{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd07195adc5b324da57c4ae5a289d8eec99dcc545f096998ea52b63cfda2645aaed",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        super().__init__()\n",
    "        self.images, self.labels = images, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitm__(self, idx):\n",
    "        image, label = self.images[idx], self.labels[idx]\n",
    "        # image = torch.FloatTensor(image)/255.\n",
    "        # label = torch.LongTensor(label)\n",
    "        # return x.view(-1, 784), y\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def get_dataloaders(batch_size, test_ratio=0.8):\n",
    "    import mnist\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    images, labels = mnist.train_images(), mnist.train_labels()\n",
    "    train_images, valid_images, train_labels, valid_labels = train_test_split(\n",
    "            images, labels, test_size=test_ratio, random_state=111)\n",
    "    test_images, test_labels = mnist.test_images(), mnist.test_labels()\n",
    "\n",
    "    train_dataset = ImageDataset(train_images, train_labels)\n",
    "    valid_dataset = ImageDataset(valid_images, valid_labels)\n",
    "    test_dataset  = ImageDataset(test_images,  test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper parameters\n",
    "n_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train images: <class 'numpy.ndarray'> (12000, 28, 28) uint8\nTrain labels: <class 'numpy.ndarray'> (12000,) uint8\nValid images: <class 'numpy.ndarray'> (48000, 28, 28) uint8\nValid labels: <class 'numpy.ndarray'> (48000,) uint8\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train_loader.dataset.images, train_loader.dataset.labels\n",
    "x_valid, y_valid = valid_loader.dataset.images, valid_loader.dataset.labels\n",
    "\n",
    "print(\"Train images:\", type(x_train), x_train.shape, x_train.dtype)\n",
    "print(\"Train labels:\", type(y_train), y_train.shape, y_train.dtype)\n",
    "print(\"Valid images:\", type(x_valid), x_valid.shape, x_valid.dtype)\n",
    "print(\"Valid labels:\", type(y_valid), y_valid.shape, y_valid.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images, labels = mnist.train_images(), mnist.train_labels()\n",
    "train_images, valid_images, train_labels, valid_labels = train_test_split(\n",
    "        images, labels, test_size=0.8, random_state=111)\n",
    "\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "train_dataset = ImageDataset(train_images, train_labels)\n",
    "\n",
    "train_dataset.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([256, 1, 28, 28]), torch.Size([256]))"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_set = datasets.MNIST('data', train=True, download=True,\n",
    "        transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "\n",
    "x, y= next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([256, 784]) torch.float32 cpu\ntorch.Size([256]) torch.int64 cpu\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        super().__init__()\n",
    "        self.images, self.labels = images, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.images[idx], self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def get_dataloader(images, labels, batch_size, shuffle=False):\n",
    "\n",
    "    ## Preprocessing\n",
    "    images = torch.from_numpy(images).view(-1, 784).float()/255.\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset=ImageDataset(images, labels),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "images, labels = mnist.train_images(), mnist.train_labels()\n",
    "train_images, valid_images, train_labels, valid_labels = train_test_split(\n",
    "            images, labels, test_size=0.8, random_state=111)\n",
    "test_images, test_labels = mnist.test_images(), mnist.test_labels()\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = get_dataloader(train_images, train_labels, batch_size, shuffle=True)\n",
    "valid_loader = get_dataloader(valid_images, valid_labels, batch_size)\n",
    "test_loader  = get_dataloader(test_images, test_labels, batch_size)\n",
    "\n",
    "x, y = next(iter(test_loader))\n",
    "print(x.shape, x.dtype, x.device)\n",
    "print(y.shape, y.dtype, y.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([256]), torch.Size([256, 10]))"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "input_size, output_size = 784, 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, output_size),\n",
    "    nn.LogSoftmax(dim=-1),\n",
    ")\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "y_hat = model(x)\n",
    "y.shape, y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.3109660148620605"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "loss_fn(y_hat, y.squeeze()).item()"
   ]
  }
 ]
}