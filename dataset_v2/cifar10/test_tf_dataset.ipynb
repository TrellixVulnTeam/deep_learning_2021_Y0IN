{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd03a227a81d8a280ae5e926c470af71c1cc02f5f6bd9a08b8bc0ce614506c13b39",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "seed = 111\n",
    "tf.random.set_seed(seed)\n",
    "n_epochs = 2\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset\n",
    "import cifar10\n",
    "from tf_modules import tf_dataloader\n",
    "\n",
    "train_data, test_data = cifar10.load_data()\n",
    "train_data, valid_data = cifar10.split_data(train_data, split_ratio=0.8)\n",
    "classes = cifar10.load_classes()\n",
    "\n",
    "train_loader = tf_dataloader(train_data, batch_size, training=True)\n",
    "valid_loader = tf_dataloader(valid_data, batch_size, training=False)\n",
    "test_loader  = tf_dataloader(test_data,  batch_size, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "from tf_modules import ConvClassifier\n",
    "\n",
    "model = ConvClassifier(output_size=10)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optim = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "79/79 [==============================] - 11s 118ms/step - loss: 0.3508 - accuracy: 0.8767 - val_loss: 1.7565 - val_accuracy: 0.5711\n",
      "Epoch 2/2\n",
      "79/79 [==============================] - 10s 115ms/step - loss: 0.3053 - accuracy: 0.8916 - val_loss: 1.5551 - val_accuracy: 0.6386\n",
      "20/20 [==============================] - 1s 66ms/step - loss: 1.5984 - accuracy: 0.6348\n",
      "test_loass: 1.5984, test_acc: 0.6348\n"
     ]
    }
   ],
   "source": [
    "## Train - Keras\n",
    "model.compile(optimizer=optim, loss=loss_fn, metrics=['accuracy'])\n",
    "model.fit(train_loader, validation_data=valid_loader, epochs=n_epochs)\n",
    "\n",
    "## Test\n",
    "test_loss, test_acc = model.evaluate(test_loader)\n",
    "print(\"test_loass: %.4f, test_acc: %.4f\" % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "79/79 [==============================] - 11s 118ms/step - loss: 0.9634 - val_loss: 3.0559\n",
      "Epoch 2/2\n",
      "79/79 [==============================] - 10s 115ms/step - loss: 0.7427 - val_loss: 2.8495\n"
     ]
    }
   ],
   "source": [
    "## Train - [1] Keras Trainer\n",
    "from tf_modules import KerasTrainer\n",
    "\n",
    "trainer = KerasTrainer(model, optim, loss_fn)\n",
    "trainer.fit(train_loader, valid_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training  10% [  8/ 79] train_loss: 0.8301\n",
      "Training  20% [ 16/ 79] train_loss: 0.6640\n",
      "Training  30% [ 24/ 79] train_loss: 0.6202\n",
      "Training  41% [ 32/ 79] train_loss: 0.5408\n",
      "Training  51% [ 40/ 79] train_loss: 0.5207\n",
      "Training  59% [ 47/ 79] train_loss: 0.5668\n",
      "Training  70% [ 55/ 79] train_loss: 0.5337\n",
      "Training  80% [ 63/ 79] train_loss: 0.4377\n",
      "Training  90% [ 71/ 79] train_loss: 0.5356\n",
      "Training 100% [ 79/ 79] train_loss: 0.6481\n",
      "Epoch [  1/  2] >>> train_loss = 0.5883, valid_loss = 2.2351, lowest_loss = 2.2351 @epoch = 1\n",
      "Training  10% [  8/ 79] train_loss: 0.5392\n",
      "Training  20% [ 16/ 79] train_loss: 0.4616\n",
      "Training  30% [ 24/ 79] train_loss: 0.4584\n",
      "Training  41% [ 32/ 79] train_loss: 0.3727\n",
      "Training  51% [ 40/ 79] train_loss: 0.3584\n",
      "Training  59% [ 47/ 79] train_loss: 0.4216\n",
      "Training  70% [ 55/ 79] train_loss: 0.3477\n",
      "Training  80% [ 63/ 79] train_loss: 0.3762\n",
      "Training  90% [ 71/ 79] train_loss: 0.3815\n",
      "Training 100% [ 79/ 79] train_loss: 0.4821\n",
      "Epoch [  2/  2] >>> train_loss = 0.4124, valid_loss = 1.6325, lowest_loss = 1.6325 @epoch = 2\n"
     ]
    }
   ],
   "source": [
    "## Train - [2] Manual trainer\n",
    "from tf_modules import ManualTrainer\n",
    "\n",
    "trainer = ManualTrainer(model, optim, loss_fn)\n",
    "trainer.fit(train_loader, valid_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">> test_loss  = 1.6782, test_acc  = 0.5250\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "from tf_modules import accuracy, average\n",
    "\n",
    "test_loss = average(loss_fn, model, test_loader)\n",
    "test_acc  = average(accuracy, model, test_loader)\n",
    "print(\">> test_loss  = %.4f, test_acc  = %.4f\" % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}